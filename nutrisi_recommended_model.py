# -*- coding: utf-8 -*-
"""Nutrisi_Recommended_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/129hEQCn16qYlHUXX78ykHUv-BBw1EsNy

### Import Library
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from tensorflow import keras

import kagglehub
import os
# Download latest version
path = kagglehub.dataset_download("nancyalaswad90/review")

print("Path to dataset files:", path)

diabetes_df = pd.read_csv(os.path.join(path, "diabetes.csv"))
print(diabetes_df.head())

"""1. Pregnancies: To express the Number of pregnancies
2. Glucose: To express the Glucose level in blood
3. BloodPressure: To express the Blood pressure measurement
4. SkinThickness: To express the thickness of the skin
5. Insulin: To express the Insulin level in blood
6. BMI: To express the Body mass index
7. DiabetesPedigreeFunction: To express the Diabetes percentage
8. Age: To express the age
9. Outcome: To express the final result 1 is Yes and 0 is No

#EDA

## Mendefinisikan Pertanyaan

1. Berapa banyak entri dalam dataset dan berapa proporsi dari masing-masing nilai Outcome (0 dan 1)?
2. Bagaimana Korelasi tiap Variabel?
3. Variabel apa yang memiliki korelasi paling tinggi dengan outcome?

## Accesing data and Cleaning
"""

diabetes_df.info()

diabetes_df.isnull().sum()

diabetes_df.duplicated().sum()

diabetes_df.describe()

# Menghapus Outlier
numerical_columns = [
    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'
]

for column in numerical_columns:
    Q1 = diabetes_df[column].quantile(0.25)
    Q3 = diabetes_df[column].quantile(0.75)
    IQR = Q3 - Q1

    maximum = Q3 + (1.5 * IQR)
    minimum = Q1 - (1.5 * IQR)

    # Menentukan kondisi untuk outlier
    kondisi_lower_than = diabetes_df[column] < minimum
    kondisi_more_than = diabetes_df[column] > maximum

    # Menghapus outlier dari DataFrame
    diabetes_df.drop(diabetes_df[kondisi_lower_than].index, inplace=True)
    diabetes_df.drop(diabetes_df[kondisi_more_than].index, inplace=True)

# Menampilkan DataFrame setelah menghapus outlier
max_min_summary = diabetes_df[numerical_columns].agg(['min', 'max']).transpose()

# Menampilkan hasil
print(max_min_summary)

diabetes_df['Pregnancies'].agg(['min', 'max'])

"""## Uji korelasi"""

correlation_matrix=diabetes_df.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

diabetes_df.groupby('Outcome').agg(
    Pregnancies_mean=('Pregnancies', 'mean'),
    Glucose_mean=('Glucose', 'mean'),
    BloodPressure_mean=('BloodPressure', 'mean'),
    SkinThickness_mean=('SkinThickness', 'mean'),
    Insulin_mean=('Insulin', 'mean'),
    BMI_mean=('BMI', 'mean'),
    DiabetesPedigreeFunction_mean=('DiabetesPedigreeFunction', 'mean'),
    Age_mean=('Age', 'mean'))



"""## Data Vizualitation and Explanatory analysis

### Data Visualitation
"""

# Menghitung jumlah untuk setiap nilai Outcome
outcome_counts = diabetes_df['Outcome'].value_counts()

# Membuat pie chart
plt.figure(figsize=(8, 6))
plt.pie(outcome_counts, labels=outcome_counts.index, autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightcoral'])
plt.title('Persentase Outcome 0 dan 1')
plt.axis('equal')  # Agar pie chart berbentuk lingkaran

# Menampilkan plot
plt.show()

# Menghitung jumlah orang yang terkena diabetes berdasarkan jumlah kehamilan
diabetes_by_pregnancies = diabetes_df[diabetes_df['Outcome'] == 1].groupby('Pregnancies').size()

# Menampilkan hasil
print(diabetes_by_pregnancies)

# Membuat visualisasi
plt.figure(figsize=(10, 6))
diabetes_by_pregnancies.plot(kind='bar', color='skyblue')
plt.title('Jumlah Orang Terkena Diabetes Berdasarkan Jumlah Kehamilan')
plt.xlabel('Jumlah Kehamilan')
plt.ylabel('Jumlah Orang')
plt.xticks(rotation=0)  # Memutar label sumbu x agar lebih mudah dibaca
plt.grid(axis='y')

# Menampilkan plot
plt.show()

# Membuat strip plot untuk Glucose berdasarkan Outcome
plt.figure(figsize=(10, 6))
sns.stripplot(x='Outcome', y='Glucose', data=diabetes_df, jitter=True, palette='Set2', alpha=0.6)
plt.title('Sebaran Glucose berdasarkan Outcome')
plt.xlabel('Outcome')
plt.ylabel('Kadar Glucose')
plt.grid(True)

# Menampilkan plot
plt.show()

"""### Explanatory Analysis

**Kesimpulan**
1. Variabel yang memiliki korelasi paling tinggi dengan Outcome (Hasil akhir, di mana 1 menunjukkan pasien menderita diabetes dan 0 menunjukkan pasien tidak menderita diabetes) adalah Glucose (kadar gula darah) dalam pasien.
2. Dan yang memiliki Korelasi paling rendah adalah SkinThickness: Ketebalan lipatan kulit triceps (mm).

**Saran**
1. Penting untuk mempertimbangkan apakah SkinThickness akan digunakan atau tidak
2. Penambahan data dalam dataset bila akurasi yang didapatkan cukup rendah

# Preprocessing
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib

"""**Mengisi nilai yang memiliki nilai 0**"""

columns_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']  # Replace with your desired columns

for column in columns_to_check:
  zero_rows = diabetes_df[diabetes_df[column] == 0]
  print(f"Rows with 0 in '{column}':\n{zero_rows}\n")

cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
diabetes_df[cols_with_zero] = diabetes_df[cols_with_zero].replace(0, np.nan)

columns_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']  # Replace with your desired columns

for column in columns_to_check:
  zero_rows = diabetes_df[diabetes_df[column] == 0]
  print(f"Rows with 0 in '{column}':\n{zero_rows}\n")

"""**Feature Scaling**"""

X = diabetes_df.drop(columns='Outcome', axis=1)
y = diabetes_df['Outcome']

# Split dengan stratifikasi agar distribusi kelas seimbang
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Modeling

## **Pemisahan Dataset** <br>

Train dan Test,
80% data untuk train dan 20% untuk test.
"""

X = diabetes_df.drop(columns='Outcome', axis=1)
y = diabetes_df['Outcome']

# Split dengan stratifikasi agar distribusi kelas seimbang
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer  # Import SimpleImputer

# Impute missing values using the mean
imputer = SimpleImputer(strategy='mean') # Create an imputer instance
X_train = imputer.fit_transform(X_train) # Fit and transform on training data
X_test = imputer.transform(X_test) # Transform test data using the trained imputer

"""## **Pemilihan Metode Model**"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Untuk menyimpan hasil
model_results = {}

def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"\n{name} Evaluation:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

    # Simpan skor ke dict
    model_results[name] = {
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1_score': f1
    }

# 1. Logistic Regression
lr = LogisticRegression(max_iter=1000)
evaluate_model("Logistic Regression", lr, X_train, y_train, X_test, y_test)

# 2. Decision Tree
dt = DecisionTreeClassifier()
evaluate_model("Decision Tree", dt, X_train, y_train, X_test, y_test)

# 3. Random Forest
rf = RandomForestClassifier()
evaluate_model("Random Forest", rf, X_train, y_train, X_test, y_test)

# 4. K-Nearest Neighbors
knn = KNeighborsClassifier()
evaluate_model("K-Nearest Neighbors", knn, X_train, y_train, X_test, y_test)

from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier

# 5. AdaBoost
ada = AdaBoostClassifier(n_estimators=100, random_state=42)
evaluate_model("AdaBoost", ada, X_train, y_train, X_test, y_test)

# 6. Gradient Boosting
gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
evaluate_model("Gradient Boosting", gb, X_train, y_train, X_test, y_test)

# Pastikan xgboost sudah terinstall dulu: pip install xgboost
from xgboost import XGBClassifier

# 7. XGBoost
xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)
evaluate_model("XGBoost", xgb, X_train, y_train, X_test, y_test)

# Tampilkan semua skor
import pandas as pd

results_df = pd.DataFrame(model_results).T
print("\nðŸ“Š Perbandingan Model:\n")
print(results_df.sort_values(by="f1_score", ascending=False))

"""Akurasi tertinggi ada di K-Nearest Neigbors

## **Fine-tunning model terbaik**
"""

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier

# Menentukan parameter grid untuk dicari
param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11],           # Jumlah tetangga
    'weights': ['uniform', 'distance'],        # Bobot tetangga
    'metric': ['euclidean', 'manhattan'],     # Metrik jarak
}

# Membuat model KNN
knn = KNeighborsClassifier()

# GridSearchCV untuk mencari hyperparameter terbaik
grid_search = GridSearchCV(estimator=knn, param_grid=param_grid,
                           cv=5, scoring='accuracy', n_jobs=-1)

# Melakukan fit pada data pelatihan
grid_search.fit(X_train, y_train)

# Mengambil hasil dari grid_search
results = grid_search.cv_results_

# Membuat DataFrame untuk memudahkan visualisasi
import pandas as pd

# Membuat DataFrame untuk melihat hasil
grid_results = pd.DataFrame(results)

# Menampilkan beberapa kolom untuk melihat hasil
grid_results[['param_n_neighbors', 'param_metric', 'param_weights', 'mean_test_score']]

# Pivot tabel berdasarkan n_neighbors dan metric untuk visualisasi
pivot_table = grid_results.pivot_table(
    values='mean_test_score',
    index='param_n_neighbors',
    columns='param_metric',
    aggfunc=np.mean
)

# Menampilkan heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(pivot_table, annot=True, cmap="YlGnBu", fmt=".3f", cbar=True)
plt.title("Heatmap of GridSearchCV Results")
plt.xlabel("Metric")
plt.ylabel("Number of Neighbors (n_neighbors)")
plt.show()

# Menggunakan model terbaik dari grid search
best_knn = grid_search.best_estimator_

# Evaluasi pada data test
y_pred = best_knn.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Assuming y_test and y_pred_best are defined from the previous code
cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

"""## Mencoba Model Deep Learning"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

from tensorflow.keras.layers import BatchNormalization

model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.summary()

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=50,
    restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=64,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=1
)

loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nTest Accuracy: {accuracy:.4f}")

y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype("int32")

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import matplotlib.pyplot as plt

# Plot akurasi
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()